---
title: "PS6"
author: "Cheng Yee Lim"
date: "17th February 2017"
output:
  github_document
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(broom)
library(modelr)
library(knitr)
library(caret)

theme_set(theme_bw())
```

```{r import, include = FALSE}
health <- read.csv("./data/mental_health.csv")
```
## Describe the data (1 point)

1. Plot a histogram of voter turnout. Make sure to give the graph a title and proper $x$ and $y$-axis labels. What is the unconditional probability of a given individual turning out to vote?
```{r}
health %>% 
  filter(!is.na(vote96)) %>%
  ggplot() + 
  geom_bar(aes(x = factor(vote96)), fill = "deepskyblue1") + 
  labs(x = "Voter Turnout", 
       y = "Count") + 
  scale_x_discrete(breaks = c(0,1), 
                   labels = c("Did not vote", "Voted"))
```
1. Generate a scatterplot of the relationship between mental health and observed voter turnout and overlay a linear smoothing line. What information does this tell us? What is problematic about this linear smoothing line?

```{r}

health %>%
  filter(!is.na(mhealth_sum) & !is.na(vote96)) %>%
  ggplot(aes(x = mhealth_sum, y = vote96)) + 
  geom_point() + 
  geom_smooth(model = "lm", color = "deepskyblue1") + 
  labs(x = "Mental Health Index", 
       y = "Voter Turnout")

```

## Basic model (3 points)

Estimate a logistic regression model of the relationship between mental health and voter turnout.

$$vote_i = \beta_0 + \beta_1 health_i$$
```{r}
m_voter <- glm(vote96 ~ mhealth_sum, data = health, family = binomial)
summary(m_voter)
```

###Is the relationship between mental health and voter turnout statistically significant?  

The relationship between mental health and voter turnout has a p-value of $3.13 * 10^{-13}$ is statistically significant at 1% significance level.  

###Interpret the estimated parameter for mental health in terms of log-odds.   
For every one-unit increase in an individual's mental health (where 0 is an individual with no depressed feelings, and 9 is an individual with the most severe depressed mood), we expect the log-odds of voting to decrease by 0.143.

###Generate a graph of the relationship between mental health and the log-odds of voter turnout.
```{r}
prob2odds <- function(x){
  x / (1 - x)
}

prob2logodds <- function(x){
  log(prob2odds(x))
}

health <- health %>%
  filter(!is.na(mhealth_sum) & mhealth_sum > 0) %>%
  add_predictions(m_voter) %>% 
  mutate(logodds = prob2logodds(pred), 
         odds = prob2odds(pred)) 

health %>% 
  ggplot(aes(x = mhealth_sum, y = logodds)) + 
  geom_line() + 
  labs(x = "Mental Health Index", 
       y = "Log-odds") 
```

###Interpret the estimated parameter for mental health in terms of odds. Generate a graph of the relationship between mental health and the odds of voter turnout.

The relationship between mental health and the odds of turning up to vote is 0.892.

```{r}
exp(-0.114)

health %>% 
  ggplot(aes(x = mhealth_sum, y = odds)) + 
  geom_line() + 
  labs(x = "Mental Health Index", 
       y = "Odds") 


```


###Interpret the estimated parameter for mental health in terms of probabilities. Generate a graph of the relationship between mental health and the probability of voter turnout. What is the first difference for an increase in the mental health index from 1 to 2? What about for 5 to 6?
The expected change in probability given an unit increase in the mental health index is -0.0273.  
The first difference for an increase in the mental health index from 1 to 2 is -0.0292.  
The first difference for an increase in the mental health index from 5 to 6 is -0.0348.  
```{r}
health %>% 
  ggplot(aes(x = mhealth_sum, y = pred)) + 
  geom_line() + 
  labs(x = "Mental Health Index", 
       y = "Predicted Probabilities") 

probability <- function(x, y){ 
  exp(1.13921 - 0.14348*y)/(1 + exp(1.13921 - 0.14348*y)) - exp(1.13921 - 0.14348*x)/(1+exp(1.13921 - 0.14348*x))
}
cat("First Difference from an increase in mental health index = ", probability(1,2))
cat("First Difference from an increase in mental health index = ", probability(5,6))

```


###Estimate the accuracy rate, proportional reduction in error (PRE), and the AUC for this model. Do you consider it to be a good model?
It is a decent model, it results in an improvement of 
```{r}
logit2prob <- function(x){
  exp(x) / (1 + exp(x))
} #logit2prob function

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
} # determining best model 

mh_accuracy <- health %>%
  filter(!is.na(mhealth_sum & !is.na(vote96))) %>%
  add_predictions(m_voter) %>%
  mutate(pred2 = logit2prob(pred),
         pred2 = as.numeric(pred > .5))

mean(mh_accuracy$vote96 == mh_accuracy$pred2, na.rm = TRUE) #accuracy rate

# function to calculate PRE for a logistic regression model
PRE <- function(model){
  # get the actual values for y from the data
  y <- model$y
  
  # get the predicted values for y from the model
  y.hat <- round(model$fitted.values)
  
  # calculate the errors for the null model and your model
  E1 <- sum(y != median(y))
  E2 <- sum(y != y.hat)
  
  # calculate the proportional reduction in error
  PRE <- (E1 - E2) / E1
  return(PRE)
}

PRE(m_voter)

confusionMatrix(mh_accuracy$pred2, mh_accuracy$vote96)

```


## Multiple variable model (3 points)

Our GLM of voter turnout consists of three components:  

Firstly, we assume our outcome variable, voter turnout, is drawn from the binomial distribution with probability $\pi$, given the values of the predicator variables in the model. $\pi$ is the probability that, for any observation $i$, $Y$ will take on the particular value $Y_i$.  
In our model, $Y_i$ takes on the expected value of 1 with probability $\pi$ and 0 with probability $1-\pi$, so $\pi_i$ is the conditional probability of sampling a 1 in this group.

```{r}
health %>% 
  filter(!is.na(vote96)) %>%
  ggplot() + 
  geom_histogram(aes(x = vote96, y = ..density..), fill = "deepskyblue1", na.rm = TRUE) + 
  labs(x = "Voter Turnout") + 
  scale_x_continuous(breaks = c(0,1), 
                   labels = c("Did not vote", "Voted")) #fix density

```

Secondly, since the probability of voter turnout may systematically vary to given known predictors, we incorporate that into the model with a linear predictor. 

$$\pi_i = \rho_i$$

Thus, the linear predictor is: 

$$g(\pi_i) \equiv \rho_i = \beta_0 + \beta_1health_i + \beta_2age_i + \beta_3educ_i + \beta_4black_i + \beta_5female_i + \beta_6married_i + \beta_7income_i + \epsilon_i$$ 

```{r}
voter <- glm(vote96 ~ mhealth_sum + age + educ + black + female + married + inc10, data = health, family = binomial)

summary(voter)
```

Thirdly, we use a logit link function to constrain the linear predictor to the [0,1] range. A link function $$g(\pi_i) = \frac{e^{\rho_i}}{1+e^{\rho_i}}$$ which transforms the expectation of the vector turnout to the linear predictor.


