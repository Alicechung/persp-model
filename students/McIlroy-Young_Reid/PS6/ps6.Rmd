---
title: "Problem Set 6"
author: "Reid McIlroy-Young"
date: "February 20, 2017"
output: html_document
---

``` {r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE)

library(tidyverse)
library(modelr)
library(pROC)
```

# Description 

``` {r, Q 1.1.1}
targetFile <- "data/mental_health.csv"
data <- read.csv(targetFile)

qplot(vote96, data=data, geom="histogram", main = "Voter turnout", binwidth = 1, xlab = 'Number of times voted', ylab ='Count') +
  scale_x_discrete(limits=c(0,1))

probVote <- sum(data$vote96, na.rm=TRUE) / length(data$vote96)


```

The probability of turning out out vote (assuming `NA`s did not vote) is `r sprintf("%.2f", probVote)`.

``` {r, Q 1.1.2}
ggplot(data, aes(mhealth_sum, vote96)) +
  geom_point() +
  geom_smooth(method = lm) +
  labs(title="Mental health score vs number of times voted",  x ="Mental health score", y = "Number of times voted") +
  scale_y_continuous(limits = c(0, 1))
```

The plot tells us that having a low mental heath score (where low means healthier) is associated more highly with voting. Unfortunately since for each score there are only 3 possible values which is much to small a range, for a linear fit to work well since it assumes the range and domain are both intervals over $\mathbb{R}$.

# Basic Model

``` {r, Q 1.2.1}
svLogit = glm(vote96 ~ mhealth_sum, data = data, family = binomial)
summary(svLogit)
```

The p-value for the mental health score's effect on voting is quite low at $3 * 10^{-13}$ which means it is statistically significant. The value is has is $-.14$ which when exponentiated gives `r exp(-.14)` $~ .8$ which is the ratio of change in voting likelihood caused by an increase in 1 on the mental health scale. This means increasing by 1 on the health scale, decreases the likelihood of voting by almost $20%$ Which indicates the relationship is substantive.

``` {r, Q 1.2.2}
#From notes
logit2prob <- function(x){
  exp(x) / (1 + exp(x))
}

prob2odds <- function(x){
  x / (1 - x)
}

prob2logodds <- function(x){
  log(prob2odds(x))
}

vote96_pred <- add_predictions(data, svLogit) 
vote96_pred <- mutate(vote96_pred, prob = logit2prob(pred))
vote96_pred <- mutate(vote96_pred, odds = prob2odds(prob))
vote96_pred <- na.omit(vote96_pred)
  
ggplot(vote96_pred, aes(mhealth_sum, pred)) +
  geom_line(color = "orange", size = 1) +
  labs(
    title = "Log odds of voting vs Mental Health rating",
    x = "Mental Health rating",
    y = "Log-odds of voting")
```

Nice linear relationship, the slope is `r svLogit$coefficients[2]` which is also the $\beta_1$ discussed above.

``` {r, Q 1.2.3}
ggplot(vote96_pred, aes(mhealth_sum, odds)) +
  geom_line(color = "orange", size = 1) +
  labs(
    title = "Odds of voting vs Mental Health rating",
    x = "Mental Health rating",
    y = "Odds of voting")
```

This plot shows the odds increasing by a factor of $e^{\beta_1}$ for each increase in mental health score, leading to the inverse curve.

``` {r, Q 1.2.4}
ggplot(vote96_pred, aes(mhealth_sum, prob)) +
  geom_line(color = "orange", size = 1) +
  labs(
    title = "Prob of voting vs Mental Health rating",
    x = "Mental Health rating",
    y = "Prob of voting")

grid <- data_grid(data, mhealth_sum)
grid <- add_predictions(grid, svLogit)
grid <- mutate(grid, prob = logit2prob(pred))

diff12 <- grid[3,] - grid[2,]
diff12 <- diff12$prob
diff56 <- grid[7,] - grid[6,]
diff56 <- diff56$prob
```

The plot shows that the probability decrease from increasing score is nearly linear.

There is a change of `r diff12` probability of voting from going from 1 to 2.

There is a change of `r diff56` probability of voting from going from 5 to 5.

``` {r, Q 1.2.5}
#From notes
PRE <- function(model){
  # get the actual values for y from the data
  y <- model$y
  
  # get the predicted values for y from the model
  y.hat <- round(model$fitted.values)
  
  # calculate the errors for the null model and your model
  E1 <- sum(y != median(y))
  E2 <- sum(y != y.hat)
  
  # calculate the proportional reduction in error
  PRE <- (E1 - E2) / E1
  return(PRE)
}


vote96_accuracy <- add_predictions(data, svLogit)
vote96_accuracy <- mutate(vote96_accuracy, pred = as.numeric(logit2prob(pred) > .5))

ac <- mean(vote96_accuracy$vote96 == vote96_accuracy$pred, na.rm = TRUE)

pre <- PRE(svLogit)

auc_val <- auc(vote96_accuracy$vote96, vote96_accuracy$pred)
```

The accuracy rate is `r ac`, the PRE is `r pre` and the AUC is `r auc_val` for this model. These indicate that the model is better than random guessing but not by a large amount (`r auc_val - .5` to be exact).

# Multivariate Model

For the model used below

+ The probability distribution is a single Bernoulli trial $Prob(vote96 == 1) = p(1 - p)$
+ The linear predictor is $g(\mu) = \beta_0 + \beta_1 mhealth\_sum + \beta_2 age + \beta_3 educ + \beta_4 black + \beta_5 female + \beta_6 married + \beta_7 inc10$
+ The link function is $p = \frac{e^{\eta}}{1 + e^{\eta}}$


``` {r, Q 1.3.2}
mvLogit <- glm(vote96 ~ . , data = data, family = binomial)

summary(mvLogit)
```


``` {r Q 2.1.1}
targetFile <- "data/gss2006.csv"
data <- na.omit(read.csv(targetFile))

tvLogit <- glm(tvhours ~ . , data = data, family = poisson)
```