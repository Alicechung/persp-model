---
title: "MACSS 30100 PS#7"
author: "Alice Mee Seon Chung"
date: "3/4/2017"
output: 

---

```{r setup, include=FALSE}
library(modelr)
library(broom)
library(tidyverse)
library(tree)
library(randomForest)
library(ggdendro)
library(forcats)
library(gbm)
library(ROCR)
library(e1071)
library(pROC)
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE,
                      error=FALSE)

options(na.action = na.warn)
options(digits = 3)
set.seed(1234)
theme_set(theme_minimal())

df_biden<- read.csv('data/biden.csv')

(df_mental <- read_csv("data/mental_health.csv") %>%
  mutate_each(funs(as.factor(.)), vote96, black, female, married) %>%
  na.omit)
(df_simpson <- read.csv('data/simpson.csv')%>%
mutate_each(funs(as.factor(.)), guilt, dem, rep, ind,
              female, black, hispanic, educ, income) %>%
  na.omit)
```


#Part1. Sexy Joe Biden 
1. 
```{r 1-1 include=FALSE}
set.seed(1234)
# split into training and validation set 
biden_split <- resample_partition(df_biden, c(test = 0.3, train = 0.7))
```

2.
```{r mse function include=FALSE}
mse <- function(model, data) {
  x <- modelr:::residuals(model, data)
  mean(x ^ 2, na.rm = TRUE)
}
```

```{r 1-2 include=FALSE}
set.seed(1234)
auto_tree <- tree(biden ~ . , data = as_tibble(biden_split$train))

# plot tree
tree_data <- dendro_data(auto_tree)
ggplot(segment(tree_data)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), 
               alpha = 0.5) +
  geom_text(data = label(tree_data), 
            aes(x = x, y = y, label = label), vjust = -0.5, size = 3) +
  geom_text(data = leaf_label(tree_data), 
            aes(x = x, y = y, label = label), vjust = 0.5, size = 3) +
  labs(title = "A decision tree to training data(biden)")+
  theme_dendro()
  
mse1<-mse(auto_tree, biden_split$test)
mse1
```
The decision tree uses biden as the reponse variable ad the other variables as predictors. It fits a decision tree to the training data and we set default values for control options. This tree model has three terminal nodes, two internal nodes, three branches. If the respondents is democratic, then the model estimates biden feeling thermometer to be 74.51. If the respondents is republican, then we proceed down the left branch to the next internal node. If the respondent is not republican( that is, independent), then the model estimates biden feeling thermometer to be 43.23. If the respondent is republican, then the model estimates biden feeling thermometer to be 57.6. The test MSE is `r mse1`.

3. Let's draw full grown tree. 

```{r 1-3 full grown tree include=FALSE}
#set.seed(1234)
full_tree <- tree(biden ~ . , data = as_tibble(biden_split$train),
                control = tree.control(nobs = nrow(biden_split$train),
                            mindev = 0))
mod_full <- full_tree

# plot tree
tree_data_full <- dendro_data(mod_full)
ggplot(segment(tree_data_full)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), 
               alpha = 0.5) +
  geom_text(data = label(tree_data_full), 
            aes(x = x, y = y, label = label), vjust = -0.5, size = 3) +
  geom_text(data = leaf_label(tree_data_full), 
            aes(x = x, y = y, label = label), vjust = 0.5, size = 3) +
  labs(title = "A decision tree to training data(biden)")+
  theme_dendro()

mse(full_tree, biden_split$test)

```

Let's use 10-fold CV to select optimal tree size
```{r 1-3 10-fold CV include=FALSE}
set.seed(1234)

# generate 10-fold CV trees
auto_cv <- crossv_kfold(df_biden, k = 10) %>%
  mutate(tree = map(train, ~ tree(biden ~ . , data = .,
                control = tree.control(nobs = nrow(df_biden),
                            mindev = 0))))

# calculate each possible prune result for each fold
auto_cv <- expand.grid(auto_cv$.id, 2:10) %>%
  as_tibble() %>%
  mutate(Var2 = as.numeric(Var2)) %>%
  rename(.id = Var1,
         k = Var2) %>%
  left_join(auto_cv) %>%
  mutate(prune = map2(tree, k, ~ prune.tree(.x, best = .y)),
         mse = map2_dbl(prune, test, mse))

auto_cv %>%
  select(k, mse) %>%
  group_by(k) %>%
  summarize(test_mse = mean(mse),
            sd = sd(mse, na.rm = TRUE)) %>%
  ggplot(aes(k, test_mse)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of terminal nodes",
       y = "Test MSE")
```
The minimum cross-validated test MSE is for 3 terminal nodes. Below is what that tree looks liks
```{r 1-3 optimal include=FALSE}
mod <- prune.tree(auto_tree, best = 3)

# plot tree
tree_data <- dendro_data(mod)
ptree <- ggplot(segment(tree_data)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), 
               alpha = 0.5) +
  geom_text(data = label(tree_data), 
            aes(x = x, y = y, label = label), 
            vjust = -0.5, size = 3) +
  geom_text(data = leaf_label(tree_data), 
            aes(x = x, y = y, label = label), vjust = 0.5, size = 3) +
  theme_dendro()
ptree
mse(mod, biden_split$test)
```

```{r, 1-4 bagging approach}
#set.seed(1234)
(biden_bag <- randomForest(biden ~ ., data = biden_split$train, importance=TRUE, mtry = 5, ntree = 500))
mse(biden_bag, biden_split$test)
```
4. The test MSE from 
```{r 1-4 bagging graph}
data_frame(var = rownames(importance(biden_bag)),
           MeanDecreaseGini = importance(biden_bag)[,1]) %>%
  mutate(var = fct_reorder(var, MeanDecreaseGini, fun = median)) %>%
  ggplot(aes(var, MeanDecreaseGini)) +
  geom_point() +
  coord_flip() +
  labs(title = "Predicting biden feeling",
       subtitle = "Bagging",
       x = NULL,
       y = "Average decrease in the Gini Index")
```

5. 
```{r, 1-5 random forest}
set.seed(1234)
(biden_bag_rf <- randomForest(biden ~ ., data = df_biden, importance = TRUE,
                             ntree = 500))
mse(biden_bag_rf, biden_split$test)
```
```{r 1-5 graph}
data_frame(var = rownames(importance(biden_bag_rf)),
           `Random forest` = importance(biden_bag_rf)[,1]) %>%
  left_join(data_frame(var = rownames(importance(biden_bag)),
           Bagging = importance(biden_bag)[,1])) %>%
  gather(model, gini, -var) %>%
  ggplot(aes(var, gini, color = model)) +
  geom_point() +
  coord_flip() +
  labs(title = "Predicting biden feeling",
       x = NULL,
       y = "Average decrease in the Gini Index",
       color = "Method")

mse_rf <- mse(biden_bag_rf, biden_split$test)
mse_rf
```

6.
```{r 1-6 boosting}
find_mse<- function(model, data){
  pred = predict(model, newdata = data, n.trees = 100)
  actual = data$data$biden
  mse = (mean((pred - actual)^2))
  return(mse)
}

# MSE
set.seed(1234)
df<- read.csv('data/biden.csv')

b_split <- resample_partition(df, c(test = 0.3, train = 0.7))
biden_boost <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000)

yhat_biden <- predict(biden_boost, 
                      newdata = b_split$test,
                      n.trees = 100)
mse <- mean((yhat_biden - b_split$test$data$biden)^2)

mes_boost<-find_mse(biden_boost, b_split$test)

# Shriankage
biden_boost_shrink1 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =0.001)
biden_boost_shrink2 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =0.01)
biden_boost_shrink3 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =0.1)
biden_boost_shrink4 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =1)
biden_boost_shrink5 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =10)
biden_boost_shrink6 <- gbm(biden ~ ., data = b_split$train, 
                 n.trees = 10000, shrinkage =100)

mse_sh1<-round(find_mse(biden_boost_shrink1, b_split$test))
mse_sh2<-round(find_mse(biden_boost_shrink2, b_split$test))
mse_sh3<-round(find_mse(biden_boost_shrink3, b_split$test))
mse_sh4<-round(find_mse(biden_boost_shrink4, b_split$test))
mse_sh5<-round(find_mse(biden_boost_shrink5, b_split$test))
mse_sh6<-round(find_mse(biden_boost_shrink6, b_split$test))

shrinkmodel <- matrix(c(mse_sh1, mse_sh2, mse_sh3, mse_sh4, mse_sh5, mse_sh6),ncol=6,byrow=TRUE)
colnames(shrinkmodel) <- c("Shrinkage = 0.001","2Shrinkage = 0.01","Shrinkage = 0.1",
                          "Shrinkage = 1","Shrinkage = 10", "Shrinkage = 100")
rownames(shrinkmodel) <- c("MSE")
shrink <- as.table(shrinkmodel)
shrink
```


#Part2 Modeling voter turnout

1. 
```{r 2 function}

PRE = function(model){
  # get the actual values for y from the data
  y <- model$y
  # get the predicted values for y from the model
  y.hat <- round(model$fitted.values)
  # calculate the errors for the null model and your model
  E1 <- sum(y != median(y))
  E2 <- sum(y != y.hat)
  # calculate the proportional reduction in error
  PRE <- (E1 - E2) / E1
  return(PRE)}

err.rate <- function(model, data) {
  data <- as_tibble(data)
  response <- as.character(model$terms[[2]])
  pred <- predict(model, newdata = data, type = "class")
  actual <- data[[response]]
  return(mean(pred != actual, na.rm = TRUE))
}


```

```{r 2-1 }
set.seed(1234)
(df_mental <- read_csv("data/mental_health.csv") %>%
  mutate_each(funs(as.factor(.)), vote96, black, female, married) %>%
  na.omit)
mh_split <- resample_partition(df_mental, c(test = 0.3, train = 0.7))
```

```{r 5 tree-based models}
set.seed(1234)
# normal tree
normal_tree <- tree(vote96 ~ . , data = as_tibble(mh_split$train))

# all multiple predictors and full grown tree
multiple_tree <- tree(vote96 ~ . , data = as_tibble(mh_split$train),
                control = tree.control(nobs = nrow(mh_split$train),
                            mindev = 0))

# finding opt tree
mh_opt_tree <- data_frame(terms = 2:10,
           model = map(terms, ~ prune.tree(multiple_tree, k = NULL, best = .)), 
           error = map_dbl(model, ~ err.rate(., data = mh_split$test)))


# plot for finding opt tree 
ggplot(mh_opt_tree, aes(terms, error)) +
  geom_line() +
  labs(title = "Comparing Tree Complexity",
       x = "Terminal Nodes",
       y = "Test Error Rate") + 
  scale_x_discrete(breaks = seq(2,10,1), limits = seq(2,10,1))

#15 nodes opt tree model
mod_opt <- prune.tree(multiple_tree, best = 6)
#The minimum cross-validation test MSE for 6 nodes. 

# bagging approach
mental_bag1 <- randomForest(vote96 ~ ., data = mh_split$train, importance=TRUE, mtry = 7, n.tree=500)



#random forest approach
mental_bag_rf <- randomForest(vote96 ~ ., data = mh_split$train,
                             ntree = 500, na.action = na.omit, importance = TRUE)

```


```{r compare 5 AUC tree }
set.seed(1234)

# single tree

#fitted_nt <- predict(mh_normaltree, as_tibble(mh_split$valid), type = 'class')
#roc_nt <- roc(as.numeric(as_tibble(mh_split$valid)$vote96), as.numeric(fitted_nt))

fitted21 <- predict(normal_tree, as_tibble(mh_split$test), type = "class")
#tree_err21 <- mean(as_tibble(mh_split$test)$vote96 != fitted21)
roc_tree21 <- roc(as.numeric(as_tibble(mh_split$test)$vote96), as.numeric(fitted21))

# multiple tree
fitted22 <- predict(multiple_tree, as_tibble(mh_split$test), type = "class")
#tree_err22 <- mean(as_tibble(mh_split$test)$vote96 != fitted22)
roc_tree22 <- roc(as.numeric(as_tibble(mh_split$test)$vote96), as.numeric(fitted22))

# opt tree
fitted23 <- predict(mod_opt, as_tibble(mh_split$test), type = "class")
#tree_err23 <- mean(as_tibble(mh_split$test)$vote96 != fitted23)
roc_tree23 <- roc(as.numeric(as_tibble(mh_split$test)$vote96), as.numeric(fitted23))

# bagging tree
fitted24 <- predict(mental_bag1, as_tibble(mh_split$test), type = "class")
#tree_err24 <- err.rate(mental_bag1, mh_split$test)
roc_tree24 <- roc(as.numeric(as_tibble(mh_split$test)$vote96), as.numeric(fitted24))

# random forest tree 
fitted25 <- predict(mental_bag_rf, as_tibble(mh_split$test), type = "class")
#tree_err25 <- mean(as_tibble(mh_split$test)$vote96 != fitted25)
roc_tree25 <- roc(as.numeric(as_tibble(mh_split$test)$vote96), as.numeric(fitted25))

#tree_err24

```

```{r compare 5 err rate and AUC with table}

err1<-err.rate(normal_tree, mh_split$test)
err2<-err.rate(multiple_tree, mh_split$test)
err3<-err.rate(mod_opt, mh_split$test)
err4<-err.rate(mental_bag1, mh_split$test)
err5<-err.rate(mental_bag_rf, mh_split$test)


auc1<-auc(roc_tree21)
auc2<-auc(roc_tree22)
auc3<-auc(roc_tree23)
auc4<-auc(roc_tree24)
auc5<- auc(roc_tree25)

treebase5medels <- matrix(c(err1, err2, err3, err4, err5, auc1, auc2, auc3, auc4, auc5),ncol=5,byrow=TRUE)
colnames(treebase5medels) <- c("Single linear","Multiple predictors linear","Optimal","Bagging","Random Forest")
rownames(treebase5medels) <- c("Test Error Rate","AUC score")
treecomparemodel <- as.table(treebase5medels)
treecomparemodel
```

```{r 2-1 plot AUC graphs tree}
# plot all together AUC
plot(roc_tree21, print.auc = TRUE, col = "blue")
plot(roc_tree22, print.auc = TRUE, col = "red", print.auc.y = .4, add = TRUE)
plot(roc_tree23, print.auc = TRUE, col = "green", print.auc.y = .4, add = TRUE)
plot(roc_tree24, print.auc = TRUE, col = "pink", print.auc.y = .4, add = TRUE)
plot(roc_tree25, print.auc = TRUE, col = "orange", print.auc.y = .3, add = TRUE)
```
```{r best random forest}

data_frame(var = rownames(importance(mental_bag_rf)),
           MeanDecreaseGini = importance(mental_bag_rf)[,1]) %>%
  mutate(var = fct_reorder(var, MeanDecreaseGini, fun = median)) %>%
  ggplot(aes(var, MeanDecreaseGini)) +
  geom_point() +
  coord_flip() +
  labs(title = "Predicting biden feeling",
       x = NULL,
       y = "Average decrease in the Gini Index",
       color = "Method")

```

2. 
```{r 2-2}
set.seed(1234)
mh_split <- resample_partition(df_mental, c(test = 0.3, train = 0.7))
```

```{r 5 SVM models}
set.seed(1234)

#single linear
mh_lin_tune <- tune(svm, vote96 ~ ., data = as_tibble(mh_split$train),
                    kernel = "linear",
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
mh_lin <- mh_lin_tune$best.model

# 2 degree polynomial kernel SVM
mh_poly2_tune <- tune(svm, vote96 ~ ., data = as_tibble(mh_split$train),
                    kernel = "polynomial", degree = 2,
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
mh_poly2 <- mh_poly2_tune$best.model

# 3 degree polynomial kernel SVM 
mh_poly3_tune <- tune(svm, vote96 ~ ., data = as_tibble(mh_split$train),
                    kernel = "polynomial", degree = 3,
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
mh_poly3 <- mh_poly3_tune$best.model

# 4 degree polynomial kernel SVM
mh_poly4_tune <- tune(svm, vote96 ~ ., data = as_tibble(mh_split$train),
                    kernel = "polynomial", degree = 4,
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
mh_poly4 <- mh_poly4_tune$best.model

# radial kernel SVM
mh_rad_tune <- tune(svm, vote96 ~ ., data = as_tibble(mh_split$train),
                    kernel = "radial",
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
mh_rad <- mh_rad_tune$best.model
```

```{r compare 5 AUC for SVM}
# single linear
fitted <- predict(mh_lin, as_tibble(mh_split$test), decision.values = TRUE) %>%
  attributes
roc_line <- roc(as_tibble(mh_split$test)$vote96, fitted$decision.values)

# 2 degree polynomial
fitted2 <- predict(mh_poly2, as_tibble(mh_split$test), decision.values = TRUE) %>%
  attributes
roc_poly2 <- roc(as_tibble(mh_split$test)$vote96, fitted2$decision.values)

# 3 degree polynomial 
fitted3 <- predict(mh_poly3, as_tibble(mh_split$test), decision.values = TRUE) %>%
  attributes
roc_poly3 <- roc(as_tibble(mh_split$test)$vote96, fitted3$decision.values)

# 4 degree polynomial
fitted4 <- predict(mh_poly4, as_tibble(mh_split$test), decision.values = TRUE) %>%
  attributes
roc_poly4 <- roc(as_tibble(mh_split$test)$vote96, fitted4$decision.values)

# radial kernel 
fitted5 <- predict(mh_rad, as_tibble(mh_split$test), decision.values = TRUE) %>%
  attributes
roc_rad <- roc(as_tibble(mh_split$test)$vote96, fitted5$decision.values)
```



```{r compare 5 err rate and ACU with table SVM}
svmerr1<-err.rate(mh_lin, mh_split$test)
svmerr2<-err.rate(mh_poly2, mh_split$test)
svmerr3<-err.rate(mh_poly3, mh_split$test)
svmerr4<-err.rate(mh_poly4, mh_split$test)
svmerr5<-err.rate(mh_rad, mh_split$test)

svmauc1<-auc(roc_line)
svmauc2<-auc(roc_poly2)
svmauc3<-auc(roc_poly3)
svmauc4<-auc(roc_poly4)
svmauc5<- auc(roc_rad)

svm5models <- matrix(c(svmerr1, svmerr2, svmerr3, svmerr4, svmerr5, 
                       svmauc1, svmauc2, svmauc3, svmauc4, svmauc5),ncol=5,byrow=TRUE)
colnames(svm5models) <- c("Single linear","2 degree","3 degree","4 degree","Radial kernel")
rownames(svm5models) <- c("Test Error Rate","AUC score")
svmcomparemodel <- as.table(svm5models)
svmcomparemodel
```

```{r compare 5 AUC for SVM models }
plot(roc_line, print.auc = TRUE, col = "blue")
plot(roc_poly2, print.auc = TRUE, col = "red", print.auc.y = .4, add = TRUE)
plot(roc_poly3, print.auc = TRUE, col = "green", print.auc.y = .4, add = TRUE)
plot(roc_poly4, print.auc = TRUE, col = "yellow", print.auc.y = .4, add = TRUE)
plot(roc_rad, print.auc = TRUE, col = "orange", print.auc.y = .3, add = TRUE)
```

```{r best SVM  3degree}
summary(mh_poly3_tune)
summary(mh_poly3)
plot(roc_poly3, print.auc.y = .3)
auc(roc_poly3)
```

# Part3 

1.
```{r split}
set.seed(1234)
oj_split <- resample_partition(df_simpson, c(test = 0.3, train = 0.7))
```

```{r oj 5 diffrent models}
set.seed(1234)
# logistic regression
oj_logit <- glm(guilt ~ black + hispanic, data = as_tibble(oj_split$train), family = 'binomial')

# tree-based model
oj_tree <- tree(guilt ~ black + hispanic, data = as_tibble(oj_split$train))

# random forest approach
oj_rf <- randomForest(guilt ~ black + hispanic, data = oj_split$train,
                             ntree = 500, na.action = na.omit)

# polynomial
oj_poly_tune <- tune(svm, guilt ~ black + hispanic, data = as_tibble(oj_split$train), 
                     kernel = "polynomial", range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
oj_poly <- oj_poly_tune$best.model

# radial kernel SVM
oj_rad_tune <- tune(svm, guilt ~ black+hispanic, data = as_tibble(oj_split$train),
                    kernel = "radial",
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
oj_rad <- oj_rad_tune$best.model

```

```{r compare oj 5 AUC SVM}

# logit
fitted_oj_logit <- predict(oj_logit, as_tibble(oj_split$test), type = 'response')
tree_err_oj_logit <- mean(as_tibble(oj_split$test)$guilt != round(fitted_oj_logit))
roc_tree_oj_logit <- roc(as.numeric(as_tibble(oj_split$test)$guilt), fitted_oj_logit)

# tree
fitted_oj_tree <- predict(oj_tree, as_tibble(oj_split$test), type = "class")
tree_err_oj_tree <- mean(as_tibble(oj_split$test)$guilt != fitted_oj_tree)
roc_tree_oj_tree <- roc(as.numeric(as_tibble(oj_split$test)$guilt), as.numeric(fitted_oj_tree))

# radom forest
fitted_oj_rf <- predict(oj_rf, as_tibble(oj_split$test), type = "class")
tree_err_oj_rf<- mean(as_tibble(oj_split$test)$guilt != fitted_oj_rf)
roc_tree_oj_rf <- roc(as.numeric(as_tibble(oj_split$test)$guilt), as.numeric(fitted_oj_rf))

# svm polynomial
fitted_oj_poly <- predict(oj_poly, as_tibble(oj_split$test), decision.values = TRUE) %>%
  attributes
svm_err_oj_poly<- err.rate(oj_poly, oj_split$test)
roc_oj_poly <- roc(as_tibble(oj_split$test)$guilt, fitted_oj_poly$decision.values)

# svm radial kernel 
fitted_oj_rad <- predict(oj_rad, as_tibble(oj_split$test), decision.values = TRUE) %>%
  attributes
svm_err_oj_rad<- err.rate(oj_rad, oj_split$test)
roc_oj_rad <- roc(as_tibble(oj_split$test)$guilt, fitted_oj_rad$decision.values)

```

```{r compare 5 err rate and ACU with table }
ojerr1<-tree_err_oj_logit
ojerr2<-tree_err_oj_tree
ojerr3<-tree_err_oj_rf
ojerr4<-svm_err_oj_poly
ojerr5<-svm_err_oj_rad

ojauc1<-auc(roc_tree_oj_logit)
ojauc2<-auc(roc_tree_oj_tree)
ojauc3<-auc(roc_tree_oj_rf)
ojauc4<-auc(roc_oj_poly)
ojauc5<- auc(roc_oj_rad)

oj5model <- matrix(c(ojerr1, ojerr2, ojerr3, ojerr4, ojerr5, ojauc1, ojauc2, ojauc3, ojauc4, ojauc5),ncol=5, byrow=TRUE)
colnames(oj5model) <- c("Logit","Tree","Random forest","Polynomial SVM","Radial kernel SVM")
rownames(oj5model) <- c("Test Error Rate","AUC score")
oj5model <- as.table(oj5model)
oj5model

```

```{r compare 5 AUC SVM }
plot(roc_tree_oj_logit, print.auc = TRUE, col = "blue")
plot(roc_tree_oj_tree, print.auc = TRUE, col = "red", print.auc.y = .4, add = TRUE)
plot(roc_tree_oj_rf, print.auc = TRUE, col = "yellow", print.auc.y = .4, add = TRUE)
plot(roc_oj_poly, print.auc = TRUE, col = "green", print.auc.y = .4, add = TRUE)
plot(roc_oj_rad, print.auc = TRUE, col = "orange", print.auc.y = .3, add = TRUE)
```
```{r oj race best  Tree}

oj_multiple_tree <- tree(guilt ~ black+hispanic , data = as_tibble(oj_split$train),
                control = tree.control(nobs = nrow(oj_split$train),
                            mindev = 0))

oj_opt_tree <- data_frame(terms = 2:10,
           model = map(terms, ~ prune.tree(oj_multiple_tree, k = NULL, best = .)), 
           error = map_dbl(model, ~ err.rate(., data = oj_split$test)))

# plot for finding opt tree 
ggplot(oj_opt_tree, aes(terms, error)) +
  geom_line() +
  labs(title = "Comparing Tree Complexity",
       x = "Terminal Nodes",
       y = "Test Error Rate") + 
  scale_x_discrete(breaks = seq(2,10,1), limits = seq(2,10,1))

oj_opt_tree_data <- dendro_data(oj_tree)
ptree_oj <- ggplot(segment(oj_opt_tree_data)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), 
               alpha = 0.5) +
  geom_text(data = label(oj_opt_tree_data), 
            aes(x = x, y = y, label = label), 
            vjust = -0.5, size = 3) +
  geom_text(data = leaf_label(oj_opt_tree_data), 
            aes(x = x, y = y, label = label), vjust = 0.5, size = 3) +
  theme_dendro()
ptree_oj

```

2.
```{r }
set.seed(1234)
oj <-select(df_simpson, -ind)
oj_split <- resample_partition(oj, c(test = 0.3, train = 0.7))
```
```{r find optimal tree}
set.seed(1234)
# all multiple predictors and full grown tree
multiple_tree_all <- tree(guilt ~ . , data = as_tibble(oj_split$train),
                control = tree.control(nobs = nrow(oj_split$train),
                            mindev = 0))

# finding opt tree
oj_opt_tree_all <- data_frame(terms = 2:10,
           model = map(terms, ~ prune.tree(multiple_tree_all, k = NULL, best = .)), 
           error = map_dbl(model, ~ err.rate(., data = oj_split$test)))


# plot for finding opt tree 
ggplot(oj_opt_tree_all, aes(terms, error)) +
  geom_line() +
  labs(title = "Comparing Tree Complexity",
       x = "Terminal Nodes",
       y = "Test Error Rate") + 
  scale_x_discrete(breaks = seq(2,10,1), limits = seq(2,10,1))

#15 nodes opt tree model
oj_opt_all <- prune.tree(multiple_tree_all, best = 7)
```

```{r oj all 5 diffrent models}
set.seed(1234)
# logistic regression
oj_logit2_all <- glm(guilt ~ ., data = as_tibble(oj_split$train), family = binomial)

# tree-based model
oj_tree2_all <- prune.tree(multiple_tree_all, best = 7)

#bagging
oj_bag2_all <- randomForest(guilt ~ ., data = oj_split$train, importance=TRUE, mtry = 9, ntree = 500)

# random forest approach
oj_rf2_all <- randomForest(guilt ~ ., data = oj_split$train,
                             ntree = 500, na.action = na.omit)

# polynomial
oj_poly_tune2_all <- tune(svm, guilt ~ ., data = as_tibble(oj_split$train), 
                     kernel = "polynomial", range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
oj_poly2_all <- oj_poly_tune2_all$best.model

# radial kernel SVM
oj_rad_tune2_all <- tune(svm, guilt ~ ., data = as_tibble(oj_split$train),
                    kernel = "radial",
                    range = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
oj_rad2_all <- oj_rad_tune2_all$best.model

```

```{r compare oj all 5 AUC SVM}

# logit
fitted_oj_logit2_all <- predict(oj_logit2_all, as_tibble(oj_split$test), type = 'response')
tree_err_oj_logit2_all <- mean(as_tibble(oj_split$test)$guilt != round(fitted_oj_logit2_all))
roc_tree_oj_logit2_all <- roc(as.numeric(as_tibble(oj_split$test)$guilt), fitted_oj_logit2_all)

# tree
fitted_oj_tree2_all <- predict(oj_tree2_all, as_tibble(oj_split$test), type = "class")
tree_err_oj_tree2_all <- mean(as_tibble(oj_split$test)$guilt != fitted_oj_tree2_all)
roc_tree_oj_tree2_all <- roc(as.numeric(as_tibble(oj_split$test)$guilt), as.numeric(fitted_oj_tree2_all))

# bagging
fitted_oj_bag2_all <- predict(oj_bag2_all, as_tibble(oj_split$test), type = "class")
tree_err_oj_bag2_all <- mean(as_tibble(oj_split$test)$guilt != fitted_oj_bag2_all)
roc_tree_oj_bag2_all <- roc(as.numeric(as_tibble(oj_split$test)$guilt), as.numeric(fitted_oj_bag2_all))

# radom forest
fitted_oj_rf2_all <- predict(oj_rf2_all, as_tibble(oj_split$test), type = "class")
tree_err_oj_rf2_all<- mean(as_tibble(oj_split$test)$guilt != fitted_oj_rf2_all)
roc_tree_oj_rf2_all <- roc(as.numeric(as_tibble(oj_split$test)$guilt), as.numeric(fitted_oj_rf2_all))

# svm polynomial
fitted_oj_poly2_all <- predict(oj_poly2_all, as_tibble(oj_split$test), decision.values = TRUE) %>%
  attributes
svm_err_oj_poly2_all<- err.rate(oj_poly2_all, oj_split$test)
roc_oj_poly2_all <- roc(as_tibble(oj_split$test)$guilt, fitted_oj_poly2_all$decision.values)

# svm radial kernel 
fitted_oj_rad2_all <- predict(oj_rad2_all, as_tibble(oj_split$test), decision.values = TRUE) %>%
  attributes
svm_err_oj_rad2_all<- err.rate(oj_rad2_all, oj_split$test)
roc_oj_rad2_all <- roc(as_tibble(oj_split$test)$guilt, fitted_oj_rad2_all$decision.values)

```

```{r compare  all 6 err rate and ACU with table }
ojerr12_all<-tree_err_oj_logit2_all
ojerr22_all<-tree_err_oj_tree2_all
ojerr32_all<-tree_err_oj_rf2_all
ojerr42_all<-svm_err_oj_poly2_all
ojerr52_all<-svm_err_oj_rad2_all
ojerr62_all<-tree_err_oj_bag2_all

ojauc12_all<-auc(roc_tree_oj_logit2_all)
ojauc22_all<-auc(roc_tree_oj_tree2_all)
ojauc32_all<-auc(roc_tree_oj_rf2_all)
ojauc42_all<-auc(roc_oj_poly2_all)
ojauc52_all<- auc(roc_oj_rad2_all)
ojauc62_all<-auc(roc_tree_oj_bag2_all)

oj6model2_all <- matrix(c(ojerr12_all, ojerr22_all, ojerr32_all, ojerr42_all, ojerr52_all, ojerr62_all,
                      ojauc12_all, ojauc22_all, ojauc32_all, ojauc42_all, ojauc52_all, ojauc62_all),
                      ncol=6, byrow=TRUE)
colnames(oj6model2_all) <- c("Logit","Tree","Random forest","Polynomial SVM","Radial kernel SVM","Bagging")
rownames(oj6model2_all) <- c("Test Error Rate","AUC score")
oj6model2_all <- as.table(oj6model2_all)
oj6model2_all

```

```{r compare 6 AUC SVM all }
plot(roc_tree_oj_logit2_all, print.auc = TRUE, col = "blue",print.auc.y = .4)
plot(roc_tree_oj_tree2_all, print.auc = TRUE, col = "red", print.auc.y = .4, add = TRUE)
plot(roc_tree_oj_rf2_all, print.auc = TRUE, col = "yellow", print.auc.y = .4, add = TRUE)
plot(roc_oj_poly2_all, print.auc = TRUE, col = "green", print.auc.y = .4, add = TRUE)
plot(roc_oj_rad2_all, print.auc = TRUE, col = "orange", print.auc.y = .3, add = TRUE)
plot(roc_tree_oj_bag2_all, print.auc = TRUE, col = "purple", print.auc.y = .3, add = TRUE)
```

```{r oj all best logit}
summary(oj_logit2_all)
```