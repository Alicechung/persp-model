---
title: "MACS 30100 PS6"
author: "Erin M. Ochoa"


date: "2017 February 20"
output:
  github_document:
    toc: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)

library(ggplot2)
library(dplyr)
library(tidyr)
library(tidyverse)
library(modelr)
library(broom)
library(forcats)
library(caret)
library(pROC)

options(na.action = na.warn)
set.seed(1234)

theme_set(theme_minimal())

options(warn=-1)
```

# Part 1: Modeling voter turnout


The 1998 General Social Survey included several questions about the respondent's mental health. `mental_health.csv` reports several important variables from this survey.

* `vote96` - 1 if the respondent voted in the 1996 presidential election, 0 otherwise
* `mhealth_sum` - index variable which assesses the respondent's mental health, ranging from 0 (an individual with no depressed mood) to 9 (an individual with the most severe depressed mood)^[The variable is an index which combines responses to four different questions: "In the past 30
days, how often did you feel: 1) so sad nothing could cheer you up, 2) hopeless, 3) that everything was an effort, and 4) worthless?" Valid responses are none of the time, a little of the time, some of the time, most of the time, and all of the time.]
* `age` - age of the respondent
* `educ` - Number of years of formal education completed by the respondent
* `black` - 1 if the respondent is black, 0 otherwise
* `female` - 1 if the respondent is female, 0 if male
* `married` - 1 if the respondent is currently married, 0 otherwise
* `inc10` - Family income, in \$10,000s


We begin by reading in the data.  Because it does not make sense to consider respondents for whom either voting behavior or depression index score is missing, we subset the data to include only those respondents with valid responses in both variables.  We also add a factor-type variable to describe voting; this will decrease the time necessary to construct plots.

```{r, read_data}
df = read.csv('data/mental_health.csv')
df = df[(!is.na(df$vote96) & !is.na(df$mhealth_sum)), ]
df$Turnout = factor(df$vote96, labels = c("Did not vote", "Voted"))
```

## Describing the data

1.  We plot a histogram of voter turnout:

```{r, vote_histogram, echo=FALSE}
ggplot(df, aes(x=Turnout, fill=Turnout)) + geom_bar() +
       ylab("Frequency count of respondents") +
       xlab("Whether the respondent voted") +
       ggtitle("Voter Turnout, 1996 Presidential Election") +
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
       panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),
       panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_y_continuous(breaks = c(0,300,600,900))
```

The unconditional probability of a given respondent voting in the election is `r mean(df$vote96)`.  The data are distributed bimodally, with about twice as many respondents voting as not voting.

1.  We generate a scatterplot of voter turnout versus depression index score, with points colored by whether the respondent voted.  Because mental health scores are integers ranging from [0,16] and turnout is categorical, there can be a maximum of 34 points on the plot.  This would not be terribly informative, so we jitter the points, increase their transparency, and add a horizontal line between the distributions of voters and non-voters; however, we must remember that the jittered position is not the true position: we must imagine the same number of points, with all the blue ones at 1 and all the red ones at 0.  (That is:  any within-group variability in the y direction is false.)  These additions are somewhat helpful, but because voter turnout is dichotomous, it is not well suited to a scatterplot.  (We will address this soon.)

```{r, scatterplot_turnout_vs_mentalhealth, echo=FALSE}

ggplot(df, aes(x=mhealth_sum, y=vote96)) + 
       geom_point(aes(color=Turnout), size=.75, alpha=.4, position="jitter") + 
       geom_hline(aes(yintercept=.5), size=1.25, color = "grey50") + 
       geom_smooth(method = "lm", color = "yellow") + 
       xlab("Depression index score") + ylab("Whether respondent voted") + 
       ggtitle("Voter Turnout, 1996 Presidential\nElection, by Depression Index Score") +
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
       panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank(),
       panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) + 
       scale_x_continuous(breaks = c(0,4,8,12,16)) +
       scale_y_continuous(breaks=0:1, labels = c("Did not vote    0","Voted    1"))
```

The regression line shows that respondents with higher depression scores trend toward not voting.  We note again, however, that because voter turnout is dichotomous—a respondent either votes (1) or doesn't (0), with no possile outcomes in between—the regression line is misleading.  It suggests, for example, that potential respondents with scores so high that they are off the index could have a negative chance of voting, which makes no sense; similarly, respondents with scores well below zero could have greater than a 1.0 chance of voting.  Additionally, because the depression index score ranges from [0,16], it does not have support over the entire domain of real numbers; the regression line, however, suggests that such scores are possible and points to probabilites for them—and some of those probabilites fall outside of the real of possible prbabilities (which range from [0,1]).  These problems imply that linear regression is the wrong type of analysis for the type of data with which we are dealing.

We now return to the matter of visualizing the distribution of depression scores by voter turnout.  Because the outcome is dichotomous and the predictor is continuous but over a short interval, the scatterplot does a poor job of clearly showing the correlation between depression score and turnout.  We therefore turn to a density plot:

```{r, density_plot, echo=FALSE}

ggplot(df, aes(mhealth_sum, fill = Turnout)) + geom_density(alpha = 0.2) + 
       xlab("Depression index score") + ylab("Proportion of respondents") + 
       ggtitle("Density Plot for Depression Index,\n1996 Presidential Election, by Voter Turnout") +
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```

Now we can clearly see that voters and non-voters had very different distributions of depression scores: most voters scored between [0,5] on the depression index, but only about half of non-voters did.  While there were voters and non-voters over nearly the entire range of possible depression scores, non-voters tended to have higher scores (but the only respondents to score 16 on the depression index were actually voters).

## Estimating a basic logistic model

First, we define the functions necessary in this section:

```{r functions_and_coeffs}
logit2prob = function(x){
  exp(x) / (1 + exp(x))
}

prob2odds = function(x){
  x / (1 - x)
}

prob2logodds = function(x){
  log(prob2odds(x))
}

calcodds = function(x){
  exp(int + coeff * x)
}

oddsratio = function(x,y){
  exp(coeff * (x - y))
}

calcprob = function(x){
  exp(int + coeff * x) / (1 + exp(int + coeff * x))
}

firstdifference = function(x,y){
  calcprob(y) - calcprob(x)
}

threshold_compare = function(thresh, dataframe, model){
  pred <- dataframe %>%
          add_predictions(model) %>%
          mutate(pred = logit2prob(pred),
          pred = as.numeric(pred > thresh))
  
  cm = confusionMatrix(pred$pred, pred$vote96, dnn = c("Prediction", "Actual"), positive = '1')

  data_frame(threshold = thresh,
             sensitivity = cm$byClass[["Sensitivity"]],
             specificity = cm$byClass[["Specificity"]],
             accuracy = cm$overall[["Accuracy"]])
}
```

We estimate a logistic regression model of the relationship between mental health and voter turnout:

```{r, basic_logistic_regression}

logit_voted_depression = glm(vote96 ~ mhealth_sum, family = binomial, data=df)
summary(logit_voted_depression)
```

We generate the additional dataframes and variables necessary to continue:
```{r bv_gen_dfs_and_vars}

int = tidy(logit_voted_depression)[1,2]
coeff = tidy(logit_voted_depression)[2,2]

voted_depression_pred = df %>%
                        add_predictions(logit_voted_depression) %>%
                        mutate(prob = logit2prob(pred)) %>%
                        mutate(odds = prob2odds(prob))

voted_depression_accuracy = df %>%
                            add_predictions(logit_voted_depression) %>%
                            mutate(pred = logit2prob(pred),
                            pred = as.numeric(pred > .5))
```

1.  We find a statistically significant relationship at the p < .001 level between depression score and voting behavior.  The relationship is negative and the coefficient is `r coeff`.  Because the model is not linear, we cannot simply say that a change in depression index score results in a corresponding change in voter turnout.  Instead, we must interpret the coefficient in terms of log-odds, odds, and probability. We will interpret the coefficient thus in the following responses.

1. Log-odds:  For every one-unit increase in depression score, we expect the log-odds of voting to decrease by `r coeff`.

We graph the relationship between mental health and the log-odds of voter turnout:

```{r, log_odds_plot, echo=FALSE}

ggplot(voted_depression_pred, aes(mhealth_sum, pred)) +
       geom_line(color="orangered1", size=1.5) +
       labs(title = "Log-odds of Voting in 1996 Presidential Election\nbased on Depression Index Score",
            x = "Depression index score",
            y = "Log-Odds of Voting") + 
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```

1. Odds: The coefficient for depression index score cannot be interpreted in terms of odds without being evaluated at a certain depression score.  This is because the relationship between depression score and odds is logistic, not linear:

$$
Odds\_of\_voting = \frac{p(depression\_index\_score)}{1 - p(depression\_index\_score)} = e^{1.13921 - (0.1434752 \times depression\_index\_score)}
$$
For example, for a respondent with a depression index score of 12 would have odds of voting equal to `r calcodds(12)`.  This means the respondent is `r calcodds(12)` times more likely to vote than not vote, because this is less than one, such a respondent would be unlikely to vote.  In contrast, a respondent with a depression index score of 3 would be `r calcodds(3)` times more likely to vote than not vote.  A respondent with a depression score of 8 would be approximately just as likely to vote as not vote because the odds for that score equal `r calcodds(8)`.

We graph the relationship between depression index score and the odds of voting:

```{r, voted_depression_odds_plot, echo=FALSE}
ggplot(voted_depression_pred, aes(mhealth_sum, odds)) +
       geom_line(color = "springgreen3", size = 1.5) +
       labs(title = "Odds of Voting Based on Depression Index Score",
            x = "Depression index score",
            y = "Odds of voting rather than not voting") +
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```

1. Probability: The relationship between depression index score and voting is not linear; like with odds, we must use a specific depression index score in order to calculate the probability of such a respondent voting.  For example, a respondent with a depression index score of 3 would have a probability of voting equal to `r calcprob(3)` and a respondent who scored 12 would have a probability of `r calcprob(12)`.  As we noted earlier, a respondent with a score of 8 would be about equally likely to vote as not vote, with a probability of `r calcprob(8)`.

The first difference for an increase in the mental health index from 1 to 2 is `r firstdifference(1,2)`; for 5 to 6, it is `r firstdifference(5,6)`.

We plot the probabilty of voting against depression score, including the actual responses as points (this time, without jitter):

```{r, logit_voted_depression_prob_plot, echo=FALSE}

ggplot(voted_depression_pred, aes(x=mhealth_sum, y=vote96)) + 
       geom_point(aes(color=Turnout), size=1.75, alpha=.15) + 
       geom_line(aes(y = prob), color = "magenta", size = 1.5) +
       labs(title = "Probability of Voting in the 1996 Presidential Election,\nbased on Depression Index Score",
            subtitle = "with Observations",
            x = "Depression index score",
            y = "Probability of voting") +
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             plot.subtitle = element_text(hjust = 0.5),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```

We define the variables necessary to answer the next question:

``` {r, ar_pre_auc}
ar = mean(voted_depression_accuracy$vote96 == voted_depression_accuracy$pred, na.rm = TRUE)

uc = median(df$vote96)

e1 = sum(df$vote96 != uc)
e2 = sum(voted_depression_accuracy$pred != uc, na.rm = TRUE)

pre = (e1 - e2) / e1

cm.5_voted_depression <- confusionMatrix(voted_depression_accuracy$pred, voted_depression_accuracy$vote96,
                         dnn = c("Prediction", "Actual"), positive = '1')

cm.5_table = cm.5_voted_depression$table


actlpos = cm.5_table[1,2] + cm.5_table[2,2]
predposcrrct = cm.5_table[2,2]

actlneg = cm.5_table[1,1] + cm.5_table[2,1]
prednegcrrct = cm.5_table[1,1]

tpr.notes =  predposcrrct / actlpos
tnr.notes =  prednegcrrct / actlneg

tpr.cm.5 = sum(cm.5_voted_depression$byClass[1])
tnr.cm.5 = sum(cm.5_voted_depression$byClass[2])


threshold_x = seq(0, 1, by = .001) %>%
              map_df(threshold_compare, df, logit_voted_depression)

auc_x_voted_depression <- auc(df$vote96, voted_depression_pred$prob)
```

1.  Using a cutoff of .5, we estimate the accuracy rate of the model at `r ar`.

We find that the useless classifier for this data predicts that all voters will vote; because the voter variable is dichotomous, we find this by simply taking the median of the distribution:  `r uc`.

With the useless classifier (which predicts all respondents will vote), we find that the proportional reduction in error is `r pre`.  This means that the model based only on depression index scores provides an improvement in the proportional reduction in error of `r 100 * pre` over the useless-classifier model.

The AUC score for this model is `r auc_x_voted_depression[1]`.

This model performs reasonably well, especially considering that it uses only one predictor. With a moderately high proportional reduction in error based on the 50% threshold as well as moderate accuracy rate and AUC, the model performs surprisingly well given the single predictor, depression index score, on which it is based.  We expect to improve the model by including additional predictors.

For good measure we plot the accuracy, sensitivity, and specificy rates for thresholds between 0 and 1:

```{r ar_vs_threshold_plot, echo=FALSE}

threshold_x %>% gather(measure, value, -threshold) %>%
            mutate(measure = factor(measure, labels = c("Accuracy", "Sensitivity (TPR)",
            "Specificity (TNR)"))) %>%
            ggplot(aes(threshold, value, color = measure, linetype = measure)) +
            geom_line() +
            labs(x = "Threshold", y = "Rate", color = "Measure", linetype = "Measure",
                 title =  "Accuracy, Sensitivity, & Specificity\nRates at Varying Thresholds") +
            theme(plot.title = element_text(hjust = 0.5, face="bold"),
            plot.subtitle = element_text(hjust = 0.5),
            panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1))
```

We also plot the ROC curve:

```{r, roc_plot, echo=FALSE}

ggplot(threshold_x, aes(1 - specificity, sensitivity)) +
       geom_line(color="darkturquoise", size=1.5) +
       geom_abline(slope = 1, linetype = 5, color = "deeppink", size=1.5) +
       labs(title =  "ROC Curve:  Voting Behavior, 1996,\nas predicted by Depression Index Score",
            x = "False Positive Rate (1 - Specificity)",
            y = "True Positive Rate (Sensitivity)") +
            theme(plot.title = element_text(hjust = 0.5, face="bold"),
            plot.subtitle = element_text(hjust = 0.5),
            panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1))
```

## Multiple variable model

Using the other variables in the dataset, derive and estimate a multiple variable logistic regression model of voter turnout.

1. Write out the three components of the GLM for your specific model of interest. This includes the
    * Probability distribution (random component): Because we are using logistic regression, we assume that the outcome (voted or did not vote) is drawn from the Bernoulli distribution, with probability $\pi$:

$$
Pr(Y_i = y_i|\pi_i) = \pi_i^{y_i}(1-\pi_i)^{(1-y_i)}
$$

    * Linear predictor: The linear predictor is the following multivariate linear model:

$$
g(\pi_i) \equiv \eta_i = \beta_0 + \beta_1DepressionIndexScore_i + \beta2Age_i + \beta_3Income10K_i
$$
     * Link function:  The link function is the logit function:

$$
\pi_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}}
$$

    
1. We estimate the model:

```{r, multivariate_logistic_regression}

#logit_voted_mv = glm(vote96 ~ age + inc10, family = binomial, data=df)
logit_voted_mv = glm(vote96 ~ mhealth_sum + age + inc10, family = binomial, data=df)

summary(logit_voted_mv)
```

We generate the additional dataframes and variables necessary to answer the question:

```{r mv_gen_df_and_vars}

int_mv = tidy(logit_voted_mv)[1,2]
coeff_mv_mh = tidy(logit_voted_mv)[2,2]
coeff_mv_age = tidy(logit_voted_mv)[3,2]
coeff_mv_inc = tidy(logit_voted_mv)[4,2]

voted_mv_pred = df[(!is.na(df$age) & !is.na(df$inc10)), ] %>%
                #data_grid(mhealth_sum, age, inc10) %>%
                add_predictions(logit_voted_mv) %>%
                mutate(prob = logit2prob(pred)) %>%
                mutate(odds = prob2odds(prob))

med_age = median(voted_mv_pred$age)
med_inc = median(voted_mv_pred$inc10)

attach(voted_mv_pred)

voted_mv_pred$age_inc = 0
voted_mv_pred$age_inc[age < med_age & inc10 >= med_inc] = 1
voted_mv_pred$age_inc[age < med_age & inc10 < med_inc] = 2
voted_mv_pred$age_inc[age >= med_age & inc10 >= med_inc] = 3
voted_mv_pred$age_inc[age >= med_age & inc10 < med_inc] = 4

voted_mv_pred$age_inc = factor(voted_mv_pred$age_inc, labels = c("Younger, higher income", "Younger, lower income", "Older, higher income", "Older, lower income"))
  
  
voted_mv_accuracy <- df[(!is.na(df$age) & !is.na(df$inc10)), ] %>%
                     add_predictions(logit_voted_mv) %>%
                     mutate(pred = logit2prob(pred),
                     pred = as.numeric(pred > .5))
```

1. Interpret the results in paragraph format. This should include a discussion of your results as if you were reviewing them with fellow computational social scientists. Discuss the results using any or all of log-odds, odds, predicted probabilities, and first differences - choose what makes sense to you and provides the most value to the reader. Use graphs and tables as necessary to support your conclusions.


We find that depression index score, age, and education are statistically significant at the p<.001 level and income (in tens of thousands) is significant at the p<.01 level.



```{r, mv_log_odds_plot, echo=FALSE}

ggplot(voted_mv_pred, aes(mhealth_sum, pred, color=age_inc)) +
       geom_line(size=1.5) +
       labs(title = "Log-odds of Voting in 1996 Presidential Election\nbased on Depression Index Score, Age, & Income",
            x = "Depression index score",
            y = "Log-Odds of Voting") + scale_color_discrete(name="Age & Income Group") + 
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```



```{r, voted_mv_odds_plot, echo=FALSE}
ggplot(voted_mv_pred, aes(mhealth_sum, odds, color = age_inc)) +
       geom_line(size = 1.5) +
       labs(title = "Odds of Voting in 1996 Presidential Election\nbased on Depression Index Score, Age, & Income",
            x = "Depression index score",
            y = "Odds of voting rather than not voting") + scale_color_discrete(name="Age & Income Group") + 
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```

```{r, logit_mv_prob_plot, echo=FALSE}

ggplot(voted_mv_pred, aes(x=mhealth_sum, y=prob, color = age_inc)) + 
       geom_line(size = 1.5) +
       labs(title = "Probability of Voting in 1996 Presidential Election\nbased on Depression Index Score, Age, & Income",
            x = "Depression index score",
            y = "Probability of voting") + scale_color_discrete(name="Age & Income Group") + 
       theme(plot.title = element_text(hjust = 0.5, face="bold"),
             panel.border = element_rect(linetype = "solid", color = "grey70", fill=NA, size=1.1)) +
       scale_x_continuous(breaks = c(0,4,8,12,16))
```




# Part 2: Modeling television consumption

We begin by reading in the data.  Having chosen the variables of interest, we subset the dataframe such that all cases contain valid responses for all such variables.  We also convert social_connect to a factor variable and label the levels.

```{r, read_data_3}
df2 = read.csv('data/gss2006.csv')
df2 = df2[(!is.na(df2$tvhours) & !is.na(df2$hrsrelax) & !is.na(df2$social_connect)), ]
df2$social_connect = factor(df2$social_connect, labels = c("Low", "Medium", "High"))
```




In this part of the problem set, you are going to derive and estimate a series of models to explain and predict TV consumption, or the number of hours of TV watched per day. As this is an event count, you will use Poisson regression to model the response variable. `gss2006.csv` contains a subset of the 2006 survey which contains many variables you can use to construct a model.

* `tvhours` - The number of hours of TV watched per day
* `age` - Age (in years)
* `childs` - Number of children
* `educ` - Highest year of formal schooling completed
* `female` - 1 if female, 0 if male
* `grass` - 1 if respondent thinks marijuana should be legalized, 0 otherwise
* `hrsrelax` - Hours per day respondent has to relax
* `black` - 1 if respondent is black, 0 otherwise
* `social_connect` - Ordinal scale of social connectedness, with values low-moderate-high (0-1-2)
* `voted04` - 1 if respondent voted in the 2004 presidential election, 0 otherwise
* `xmovie` - 1 if respondent saw an X-rated movie in the last year, 0 otherwise
* `zodiac` - Respondent's [astrological sign](https://en.wikipedia.org/wiki/Astrological_sign)

## Estimate a regression model (3 points)

Using the other variables in the dataset, derive and estimate a multiple variable Poisson regression model of hours of TV watched.

1. Write out the three components of the GLM for your specific model of interest. This includes the
    * Probability distribution (random component)
    * Linear predictor
    * Link function
1. Estimate the model and report your results.




We estimate a Poisson model to explain television consumption with leisure time and social connectedness:

```{r, poisson_model}

poisson_tv <- glm(tvhours ~ hrsrelax + social_connect, family = "quasipoisson", data = df2)
summary(poisson_tv)

```


```{r, poisson_log_count_plot}
df2 %>%
  data_grid(hrsrelax, social_connect) %>%
  add_predictions(poisson_tv) %>%
  ggplot(aes(hrsrelax, pred, color=social_connect)) +
  geom_line(size = 1.5) +
  labs(x = "Hours of Relaxation",
       y = "Predicted log-count of television hours")
```



```{r, poisson_tv_predicted_count_plot}
df2 %>%
  data_grid(hrsrelax, social_connect) %>%
  add_predictions(poisson_tv) %>%
  mutate(pred = exp(pred)) %>%
  ggplot(aes(hrsrelax, pred, color=social_connect)) +
  geom_line(size=1.5) +
  labs(x = "Hours of Relaxation",
       y = "Predicted count of television hours")
```

1. Interpret the results in paragraph format. This should include a discussion of your results as if you were reviewing them with fellow computational social scientists. Discuss the results using any or all of log-counts, predicted event counts, and first differences - choose what makes sense to you and provides the most value to the reader. Is the model over or under-dispersed? Use graphs and tables as necessary to support your conclusions.

# Submission instructions

Assignment submission will work the same as earlier assignments. Submit your work as a pull request before the start of class on Monday. Store it in the same locations as you've been using. However the format of your submission should follow the procedures outlined below.

## If you use R

Submit your assignment as a single [R Markdown document](http://rmarkdown.rstudio.com/). R Markdown is similar to Juptyer Notebooks and compiles all your code, output, and written analysis in a single reproducible file.

